# ======================================================
# ğŸ”¹ DATA PREPROCESSING â€” Steam Reviews Big Data Project
#    (sesuai pipeline: setelah cleaning, sebelum modeling)
# ======================================================

import os
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split

# 0) Path I/O
IN_PATH  = "/content/drive/MyDrive/BigData_Steam/data/processed/steam_reviews_clean.csv"
OUT_DIR  = "/content/drive/MyDrive/BigData_Steam/data/processed"
OUT_PATH = os.path.join(OUT_DIR, "steam_reviews_preprocessed.csv")

os.makedirs(OUT_DIR, exist_ok=True)

# 1) Load & cek ringkas
df = pd.read_csv(IN_PATH)
print("âœ… Loaded:", IN_PATH, "| shape:", df.shape)
print(df.head(2), "\n")

print("INFO BEFORE:\n", df.info(), "\n")
print("MISSING BEFORE:\n", df.isna().sum(), "\n")

# 2) Drop kolom yang tidak dipakai untuk model numerik awal
drop_cols = ["appid", "name", "release_date", "review"]  # 'review' teks mentah (NLP nanti)
df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors="ignore")

# 3) Pastikan tipe & tangani NaN kolom numerik inti
num_cols = ["word_count", "votes_up", "votes_funny", "author_playtime_forever", "price"]
for c in num_cols:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0)

# Target kolom
if "voted_up" in df.columns:
    # pastikan boolean
    df["voted_up"] = df["voted_up"].astype(bool)
else:
    raise ValueError("Kolom 'voted_up' tidak ditemukan di dataset cleaned.")

# (opsional) Jika timestamp masih integer dan kamu butuh untuk EDA waktu, bisa konversi terpisah
# if "timestamp_created" in df.columns and pd.api.types.is_numeric_dtype(df["timestamp_created"]):
#     df["timestamp_created_dt"] = pd.to_datetime(df["timestamp_created"], unit="s")

# 4) Feature engineering sederhana
def bucket_wc(x: float) -> str:
    return "short" if x < 20 else ("medium" if x < 100 else "long")

df["review_length"] = df["word_count"].apply(bucket_wc)

# (opsional) fitur jam main â€” tidak wajib kalau sudah pakai menit
# df["playtime_hours"] = df["author_playtime_forever"] / 60.0

# 5) Encoding kategorikal
le = LabelEncoder()
df["review_length_encoded"] = le.fit_transform(df["review_length"])

# 6) Scaling fitur numerik (standarisasi)
scale_cols = [c for c in num_cols if c in df.columns]
scaler = StandardScaler()
df[scale_cols] = scaler.fit_transform(df[scale_cols])

# 7) Simpan hasil preprocessed (siap untuk modeling)
df.to_csv(OUT_PATH, index=False)
print(f"ğŸ’¾ Saved preprocessed dataset: {OUT_PATH} | shape: {df.shape}")

print("\nINFO AFTER:\n", df.info(), "\n")
print("MISSING AFTER:\n", df.isna().sum(), "\n")
print("Preview cols:", df.columns.tolist())

# 8) (Opsional) Split trainâ€“test untuk klasifikasi 'voted_up'
FEATURE_COLS = [c for c in (num_cols + ["review_length_encoded"]) if c in df.columns]
TARGET_COL   = "voted_up"

X = df[FEATURE_COLS].copy()
y = df[TARGET_COL].astype(bool).copy()

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

print(f"\nâœ… Split done. Train: {len(X_train)}, Test: {len(X_test)}")
print("Features used:", FEATURE_COLS)

# (opsional) Simpan split ke CSV agar modeling tinggal load
X_train.to_csv(os.path.join(OUT_DIR, "X_train.csv"), index=False)
X_test.to_csv(os.path.join(OUT_DIR, "X_test.csv"), index=False)
y_train.to_csv(os.path.join(OUT_DIR, "y_train.csv"), index=False)
y_test.to_csv(os.path.join(OUT_DIR, "y_test.csv"), index=False)
print("ğŸ’¾ Saved train/test splits to:", OUT_DIR)
