# ============================================================
# ðŸ”¹ STEAM REVIEW SCRAPER â€” schema identik dgn Kaggle referensi
#    Kolom: 11 kolom [appid, review, word_count, voted_up, votes_up,
#                     votes_funny, timestamp_created, author_playtime_forever,
#                     name, price, release_date]
#    Catatan kesesuaian:
#    - price = cent (int64), bukan dibagi 100
#    - author_playtime_forever = menit (int64), bukan jam
#    - release_date = float64 (NaN), disamakan dengan file referensi
# ============================================================

# 1ï¸âƒ£ Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2ï¸âƒ£ Import library
import os, time, requests
import pandas as pd
import numpy as np
from typing import Dict, Any, Optional
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter

# 3ï¸âƒ£ Lokasi simpan
BASE_DIR = "/content/drive/MyDrive/BigData_Steam/data/raw"
os.makedirs(BASE_DIR, exist_ok=True)
OUTPUT_PATH = os.path.join(BASE_DIR, "steam_reviews_realtime_11cols.csv")

# 4ï¸âƒ£ App list (bebas kamu ganti/extend)
APP_IDS = [
    570,      # Dota 2
    1172470,  # Apex Legends
    578080,   # PUBG: BATTLEGROUNDS
    271590,   # Grand Theft Auto V
]

# 5ï¸âƒ£ Parameter scraping
MAX_REVIEWS_PER_APP = 2100
LANGUAGE = "english"
SLEEP_SEC = 1.0
MAX_RETRIES = 3
BACKOFF_BASE = 1.5
STORE_CC = "us"   # gunakan 'us' agar price_overview lebih konsisten; tetap output dlm cent

# ðŸ”§ HTTP session (retry + UA)
session = requests.Session()
retry = Retry(
    total=5,
    backoff_factor=0.6,
    status_forcelist=(429, 500, 502, 503, 504),
    allowed_methods=frozenset(["GET"]),
)
session.mount("https://", HTTPAdapter(max_retries=retry))
HEADERS = {"User-Agent": "Mozilla/5.0 SteamReviewCollector/1.0 (Colab)"}

# 6ï¸âƒ£ Skema & dtypes target (PERSIS seperti referensi)
REQUIRED_COLS = [
    "appid", "review", "word_count", "voted_up", "votes_up", "votes_funny",
    "timestamp_created", "author_playtime_forever", "name", "price", "release_date"
]
DTYPES_ENFORCE = {
    "appid": "int64",
    "review": "object",
    "word_count": "int64",
    "voted_up": "bool",
    "votes_up": "int64",
    "votes_funny": "int64",
    "timestamp_created": "int64",
    "author_playtime_forever": "int64",  # menit
    "name": "object",
    "price": "int64",                    # cent (tanpa /100)
    "release_date": "float64"            # NaN (float64), samakan dengan referensi
}

# 7ï¸âƒ£ Ambil metadata app (name, price in cent, release_date=NaN biar float64)
_cache_appinfo: Dict[int, Dict[str, Any]] = {}

def get_app_details(app_id: int) -> Dict[str, Any]:
    if app_id in _cache_appinfo:
        return _cache_appinfo[app_id]

    url = "https://store.steampowered.com/api/appdetails"
    params = {"appids": app_id, "cc": STORE_CC, "l": "en"}

    for attempt in range(MAX_RETRIES):
        try:
            r = session.get(url, headers=HEADERS, params=params, timeout=20)
            r.raise_for_status()
            j = r.json()
            node = j.get(str(app_id), {})
            if node.get("success"):
                data = node.get("data", {}) or {}
                pov = data.get("price_overview") or {}
                is_free = bool(data.get("is_free", False))

                # 'final' = cent; simpan sebagai int64
                final_cent = pov.get("final")
                if is_free or final_cent is None:
                    price_cent = 0
                else:
                    # kadang float/str -> paksa ke int
                    price_cent = int(float(final_cent))

                result = {
                    "name": data.get("name") or "",
                    "price": price_cent,    # int64
                    "release_date": np.nan  # float64 NaN (samakan referensi)
                }
                _cache_appinfo[app_id] = result
                return result
        except Exception:
            time.sleep(BACKOFF_BASE ** attempt)

    # fallback
    result = {"name": "", "price": 0, "release_date": np.nan}
    _cache_appinfo[app_id] = result
    return result

# 8ï¸âƒ£ Scrape review per app
def fetch_reviews_for_app(app_id: int, max_reviews: int) -> pd.DataFrame:
    rows, cursor, pulled = [], "*", 0
    seen = set()

    meta = get_app_details(app_id)
    g_name, g_price, g_release = meta["name"], meta["price"], meta["release_date"]

    while pulled < max_reviews:
        url = f"https://store.steampowered.com/appreviews/{app_id}"
        params = {
            "json": 1,
            "cursor": cursor,
            "num_per_page": 100,
            "filter": "recent",
            "language": LANGUAGE,
            "review_type": "all",
            "purchase_type": "all",
        }

        ok, data = False, None
        for attempt in range(MAX_RETRIES):
            try:
                resp = session.get(url, headers=HEADERS, params=params, timeout=30)
                resp.raise_for_status()
                data = resp.json()
                ok = True
                break
            except Exception:
                time.sleep(BACKOFF_BASE ** attempt)

        if not ok or not data or "reviews" not in data:
            break

        revs = data.get("reviews") or []
        if not revs:
            break

        for rv in revs:
            txt = (rv.get("review") or "").strip()
            if not txt:
                continue

            # playtime dalam MENIT (int64)
            pt_min = (rv.get("author") or {}).get("playtime_forever")
            try:
                pt_min = int(pt_min) if pt_min is not None else 0
            except Exception:
                pt_min = 0

            rows.append({
                "appid": int(app_id),
                "review": txt,
                "word_count": int(len(txt.split())),
                "voted_up": bool(rv.get("voted_up")),
                "votes_up": int(rv.get("votes_up") or 0),
                "votes_funny": int(rv.get("votes_funny") or 0),
                "timestamp_created": int(rv.get("timestamp_created") or 0),
                "author_playtime_forever": pt_min,   # menit (int)
                "name": g_name,
                "price": int(g_price or 0),          # cent (int)
                "release_date": g_release            # float64 NaN
            })

        pulled += len(revs)

        next_cursor = data.get("cursor")
        if not next_cursor or next_cursor in seen:
            break
        seen.add(next_cursor)
        cursor = next_cursor

        time.sleep(SLEEP_SEC)
        if pulled >= max_reviews:
            break

    df = pd.DataFrame(rows)

    # Pastikan semua kolom ada & urutan sama
    for c in REQUIRED_COLS:
        if c not in df.columns:
            df[c] = np.nan
    df = df[REQUIRED_COLS]

    return df

# 9ï¸âƒ£ Jalankan untuk semua app
frames = []
for app in APP_IDS:
    print(f"[INFO] Fetch up to {MAX_REVIEWS_PER_APP} for app_id={app} ...")
    df_app = fetch_reviews_for_app(app, MAX_REVIEWS_PER_APP)
    got = len(df_app)
    label = df_app["name"].iloc[0] if got else str(app)
    print(f" -> Got {got} rows for {label}")
    frames.append(df_app)

df_s = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame(columns=REQUIRED_COLS)

# ðŸ”Ÿ Enforce dtype PERSIS (int64/bool/object/float64)
# - int64 tidak menerima NaN â†’ isi 0 dulu supaya dtype tetap int64
int_cols = ["appid","word_count","votes_up","votes_funny","timestamp_created","author_playtime_forever","price"]
for c in int_cols:
    df_s[c] = pd.to_numeric(df_s[c], errors="coerce").fillna(0).astype("int64")

df_s["voted_up"] = df_s["voted_up"].astype(bool)
df_s["review"] = df_s["review"].astype(object)
df_s["name"] = df_s["name"].astype(object)
df_s["release_date"] = pd.to_numeric(df_s["release_date"], errors="coerce").astype("float64")

# Optional: drop duplicates (appid + timestamp + review)
if not df_s.empty:
    before = len(df_s)
    df_s = df_s.drop_duplicates(subset=["appid","timestamp_created","review"])
    after = len(df_s)
    if after != before:
        print(f"[INFO] Dropped duplicates: {before - after}")

# Simpan
df_s = df_s[REQUIRED_COLS]
df_s.to_csv(OUTPUT_PATH, index=False)
print(f"\nâœ… Saved to: {OUTPUT_PATH}")
print(f"Total rows: {len(df_s)}")

print("\n[SUMMARY] dtypes:")
print(df_s.dtypes)

print("\n[SUMMARY] Rows per app_id:")
print(df_s.groupby("appid")["review"].count().sort_values(ascending=False))
